{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle = True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.2.0'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Prashant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "\n",
    "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "['This', 'disk', 'has', 'failed', 'many', 'times.', 'I', 'would', 'like', 'to', 'get', 'it', 'replaced.']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['disk', 'fail', 'time', 'like', 'replac']\n"
     ]
    }
   ],
   "source": [
    "document_num = 50\n",
    "doc_sample = 'This disk has failed many times. I would like to get it replaced.'\n",
    "\n",
    "print(\"Original document: \")\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in newsgroups_train.data:\n",
    "    processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lerxst', 'thing', 'subject', 'nntp', 'post', 'host', 'organ', 'univers', 'maryland', 'colleg', 'park', 'line', 'wonder', 'enlighten', 'door', 'sport', 'look', 'late', 'earli', 'call', 'bricklin', 'door', 'small', 'addit', 'bumper', 'separ', 'rest', 'bodi', 'know', 'tellm', 'model', 'engin', 'spec', 'year', 'product', 'histori', 'info', 'funki', 'look', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst'], ['guykuo', 'carson', 'washington', 'subject', 'clock', 'poll', 'final', 'summari', 'final', 'clock', 'report', 'keyword', 'acceler', 'clock', 'upgrad', 'articl', 'shelley', 'qvfo', 'innc', 'organ', 'univers', 'washington', 'line', 'nntp', 'post', 'host', 'carson', 'washington', 'fair', 'number', 'brave', 'soul', 'upgrad', 'clock', 'oscil', 'share', 'experi', 'poll', 'send', 'brief', 'messag', 'detail', 'experi', 'procedur', 'speed', 'attain', 'rat', 'speed', 'card', 'adapt', 'heat', 'sink', 'hour', 'usag', 'floppi', 'disk', 'function', 'floppi', 'especi', 'request', 'summar', 'day', 'network', 'knowledg', 'base', 'clock', 'upgrad', 'haven', 'answer', 'poll', 'thank', 'guykuo', 'washington']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<61411 unique tokens: ['addit', 'bodi', 'bricklin', 'bring', 'bumper']...>\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1434392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_pos  # Total number of corpus positions (number of processed words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_docs   # Number of documents processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17: 2,\n",
       " 37: 2080,\n",
       " 34: 11314,\n",
       " 24: 4777,\n",
       " 27: 5858,\n",
       " 13: 4849,\n",
       " 25: 10894,\n",
       " 38: 4609,\n",
       " 21: 101,\n",
       " 6: 527,\n",
       " 26: 269,\n",
       " 18: 11282,\n",
       " 39: 706,\n",
       " 10: 55,\n",
       " 7: 221,\n",
       " 33: 229,\n",
       " 19: 2212,\n",
       " 16: 307,\n",
       " 8: 372,\n",
       " 5: 1120,\n",
       " 2: 4,\n",
       " 31: 606,\n",
       " 0: 400,\n",
       " 4: 35,\n",
       " 30: 288,\n",
       " 29: 448,\n",
       " 1: 380,\n",
       " 15: 3857,\n",
       " 35: 2,\n",
       " 22: 426,\n",
       " 9: 945,\n",
       " 32: 163,\n",
       " 40: 2063,\n",
       " 28: 560,\n",
       " 12: 407,\n",
       " 14: 675,\n",
       " 11: 8,\n",
       " 20: 1444,\n",
       " 36: 2057,\n",
       " 3: 543,\n",
       " 23: 39,\n",
       " 61: 9,\n",
       " 50: 58,\n",
       " 88: 446,\n",
       " 51: 202,\n",
       " 72: 55,\n",
       " 58: 577,\n",
       " 85: 549,\n",
       " 76: 613,\n",
       " 66: 957,\n",
       " 41: 172,\n",
       " 86: 199,\n",
       " 44: 5353,\n",
       " 80: 53,\n",
       " 74: 1,\n",
       " 65: 2,\n",
       " 57: 413,\n",
       " 70: 1181,\n",
       " 47: 127,\n",
       " 82: 186,\n",
       " 71: 26,\n",
       " 79: 327,\n",
       " 56: 727,\n",
       " 78: 941,\n",
       " 48: 104,\n",
       " 68: 824,\n",
       " 53: 356,\n",
       " 73: 107,\n",
       " 83: 498,\n",
       " 45: 24,\n",
       " 75: 264,\n",
       " 49: 705,\n",
       " 42: 134,\n",
       " 63: 122,\n",
       " 81: 72,\n",
       " 64: 305,\n",
       " 87: 63,\n",
       " 59: 169,\n",
       " 54: 431,\n",
       " 60: 353,\n",
       " 55: 480,\n",
       " 77: 376,\n",
       " 84: 61,\n",
       " 52: 565,\n",
       " 69: 494,\n",
       " 67: 341,\n",
       " 46: 898,\n",
       " 62: 451,\n",
       " 43: 768,\n",
       " 170: 1,\n",
       " 148: 156,\n",
       " 167: 284,\n",
       " 173: 55,\n",
       " 149: 1776,\n",
       " 105: 2713,\n",
       " 113: 285,\n",
       " 142: 344,\n",
       " 115: 1267,\n",
       " 114: 31,\n",
       " 172: 84,\n",
       " 161: 1234,\n",
       " 127: 755,\n",
       " 160: 4,\n",
       " 131: 322,\n",
       " 129: 624,\n",
       " 159: 49,\n",
       " 124: 278,\n",
       " 140: 373,\n",
       " 143: 53,\n",
       " 132: 810,\n",
       " 98: 206,\n",
       " 122: 748,\n",
       " 158: 273,\n",
       " 93: 567,\n",
       " 103: 41,\n",
       " 154: 221,\n",
       " 125: 68,\n",
       " 110: 583,\n",
       " 119: 1153,\n",
       " 164: 570,\n",
       " 95: 514,\n",
       " 163: 141,\n",
       " 94: 140,\n",
       " 89: 806,\n",
       " 130: 2,\n",
       " 155: 96,\n",
       " 145: 624,\n",
       " 106: 302,\n",
       " 128: 3861,\n",
       " 136: 390,\n",
       " 116: 2062,\n",
       " 153: 632,\n",
       " 123: 254,\n",
       " 104: 387,\n",
       " 146: 1117,\n",
       " 165: 47,\n",
       " 111: 710,\n",
       " 96: 1228,\n",
       " 118: 1189,\n",
       " 162: 252,\n",
       " 117: 2344,\n",
       " 157: 23,\n",
       " 137: 1076,\n",
       " 138: 2557,\n",
       " 174: 363,\n",
       " 166: 1285,\n",
       " 156: 412,\n",
       " 133: 542,\n",
       " 90: 448,\n",
       " 152: 318,\n",
       " 151: 932,\n",
       " 141: 772,\n",
       " 97: 3,\n",
       " 112: 465,\n",
       " 91: 1098,\n",
       " 171: 609,\n",
       " 101: 127,\n",
       " 147: 401,\n",
       " 121: 1629,\n",
       " 120: 2,\n",
       " 139: 476,\n",
       " 92: 665,\n",
       " 108: 783,\n",
       " 134: 1286,\n",
       " 150: 1498,\n",
       " 168: 2832,\n",
       " 144: 32,\n",
       " 100: 118,\n",
       " 107: 256,\n",
       " 99: 116,\n",
       " 102: 294,\n",
       " 109: 72,\n",
       " 169: 344,\n",
       " 126: 197,\n",
       " 135: 12,\n",
       " 189: 19,\n",
       " 177: 13,\n",
       " 184: 191,\n",
       " 209: 14,\n",
       " 185: 127,\n",
       " 206: 828,\n",
       " 182: 403,\n",
       " 211: 1930,\n",
       " 193: 599,\n",
       " 208: 973,\n",
       " 202: 548,\n",
       " 191: 5,\n",
       " 201: 5,\n",
       " 207: 652,\n",
       " 212: 6562,\n",
       " 175: 2,\n",
       " 187: 109,\n",
       " 179: 302,\n",
       " 183: 469,\n",
       " 178: 591,\n",
       " 192: 512,\n",
       " 205: 581,\n",
       " 198: 654,\n",
       " 194: 555,\n",
       " 199: 2,\n",
       " 180: 332,\n",
       " 200: 735,\n",
       " 197: 1572,\n",
       " 176: 641,\n",
       " 196: 716,\n",
       " 188: 1150,\n",
       " 181: 498,\n",
       " 203: 65,\n",
       " 195: 1253,\n",
       " 204: 473,\n",
       " 186: 64,\n",
       " 190: 96,\n",
       " 210: 64,\n",
       " 230: 561,\n",
       " 229: 166,\n",
       " 236: 16,\n",
       " 247: 97,\n",
       " 234: 168,\n",
       " 248: 11,\n",
       " 214: 29,\n",
       " 239: 45,\n",
       " 218: 187,\n",
       " 240: 1,\n",
       " 254: 2,\n",
       " 215: 60,\n",
       " 233: 3,\n",
       " 228: 4,\n",
       " 255: 7,\n",
       " 241: 123,\n",
       " 221: 675,\n",
       " 219: 23,\n",
       " 261: 249,\n",
       " 238: 498,\n",
       " 259: 83,\n",
       " 257: 22,\n",
       " 227: 390,\n",
       " 250: 505,\n",
       " 226: 70,\n",
       " 242: 25,\n",
       " 244: 453,\n",
       " 223: 409,\n",
       " 260: 19,\n",
       " 225: 163,\n",
       " 237: 1599,\n",
       " 245: 398,\n",
       " 256: 794,\n",
       " 216: 489,\n",
       " 217: 86,\n",
       " 249: 937,\n",
       " 220: 652,\n",
       " 246: 1877,\n",
       " 258: 417,\n",
       " 213: 414,\n",
       " 253: 70,\n",
       " 251: 4,\n",
       " 222: 499,\n",
       " 243: 1205,\n",
       " 232: 111,\n",
       " 252: 1570,\n",
       " 224: 59,\n",
       " 235: 10,\n",
       " 231: 383,\n",
       " 358: 5,\n",
       " 295: 5,\n",
       " 290: 148,\n",
       " 332: 8,\n",
       " 339: 917,\n",
       " 266: 168,\n",
       " 300: 955,\n",
       " 356: 229,\n",
       " 346: 94,\n",
       " 351: 56,\n",
       " 322: 4,\n",
       " 321: 24,\n",
       " 357: 37,\n",
       " 305: 12,\n",
       " 304: 870,\n",
       " 309: 130,\n",
       " 336: 13,\n",
       " 312: 87,\n",
       " 286: 76,\n",
       " 324: 969,\n",
       " 314: 226,\n",
       " 359: 267,\n",
       " 310: 1111,\n",
       " 280: 608,\n",
       " 262: 49,\n",
       " 283: 2,\n",
       " 311: 235,\n",
       " 315: 2189,\n",
       " 279: 937,\n",
       " 296: 853,\n",
       " 302: 427,\n",
       " 331: 688,\n",
       " 316: 56,\n",
       " 284: 434,\n",
       " 313: 336,\n",
       " 270: 398,\n",
       " 293: 831,\n",
       " 345: 1764,\n",
       " 275: 2046,\n",
       " 287: 176,\n",
       " 281: 259,\n",
       " 271: 1434,\n",
       " 299: 981,\n",
       " 348: 987,\n",
       " 317: 138,\n",
       " 319: 112,\n",
       " 272: 58,\n",
       " 318: 51,\n",
       " 326: 176,\n",
       " 263: 662,\n",
       " 306: 444,\n",
       " 297: 804,\n",
       " 342: 319,\n",
       " 273: 69,\n",
       " 282: 1029,\n",
       " 352: 450,\n",
       " 334: 13,\n",
       " 285: 332,\n",
       " 289: 188,\n",
       " 338: 2244,\n",
       " 320: 23,\n",
       " 337: 23,\n",
       " 274: 28,\n",
       " 347: 260,\n",
       " 349: 8,\n",
       " 341: 41,\n",
       " 340: 108,\n",
       " 269: 213,\n",
       " 333: 65,\n",
       " 288: 367,\n",
       " 264: 115,\n",
       " 301: 238,\n",
       " 294: 1232,\n",
       " 353: 251,\n",
       " 307: 665,\n",
       " 298: 108,\n",
       " 291: 305,\n",
       " 329: 237,\n",
       " 327: 290,\n",
       " 328: 1303,\n",
       " 330: 221,\n",
       " 325: 517,\n",
       " 268: 451,\n",
       " 276: 448,\n",
       " 350: 291,\n",
       " 355: 188,\n",
       " 292: 462,\n",
       " 265: 741,\n",
       " 308: 484,\n",
       " 267: 155,\n",
       " 278: 972,\n",
       " 335: 165,\n",
       " 343: 524,\n",
       " 277: 623,\n",
       " 354: 707,\n",
       " 344: 383,\n",
       " 303: 53,\n",
       " 323: 85,\n",
       " 361: 5,\n",
       " 379: 36,\n",
       " 390: 113,\n",
       " 364: 279,\n",
       " 375: 79,\n",
       " 368: 5,\n",
       " 363: 209,\n",
       " 389: 9,\n",
       " 387: 164,\n",
       " 380: 2442,\n",
       " 376: 100,\n",
       " 365: 292,\n",
       " 381: 321,\n",
       " 360: 1,\n",
       " 366: 310,\n",
       " 370: 695,\n",
       " 362: 64,\n",
       " 377: 12,\n",
       " 382: 65,\n",
       " 367: 9,\n",
       " 384: 22,\n",
       " 386: 3411,\n",
       " 378: 953,\n",
       " 385: 1402,\n",
       " 372: 137,\n",
       " 374: 531,\n",
       " 388: 1243,\n",
       " 369: 407,\n",
       " 371: 819,\n",
       " 383: 47,\n",
       " 373: 99,\n",
       " 397: 21,\n",
       " 403: 28,\n",
       " 429: 68,\n",
       " 414: 22,\n",
       " 440: 181,\n",
       " 426: 67,\n",
       " 402: 12,\n",
       " 432: 76,\n",
       " 433: 4,\n",
       " 424: 227,\n",
       " 395: 419,\n",
       " 453: 134,\n",
       " 411: 6,\n",
       " 409: 24,\n",
       " 413: 228,\n",
       " 405: 345,\n",
       " 392: 667,\n",
       " 422: 1161,\n",
       " 445: 23,\n",
       " 416: 47,\n",
       " 431: 1830,\n",
       " 419: 402,\n",
       " 415: 42,\n",
       " 423: 576,\n",
       " 455: 117,\n",
       " 449: 319,\n",
       " 448: 457,\n",
       " 421: 769,\n",
       " 435: 253,\n",
       " 400: 225,\n",
       " 391: 74,\n",
       " 446: 683,\n",
       " 442: 607,\n",
       " 398: 42,\n",
       " 430: 830,\n",
       " 418: 361,\n",
       " 434: 96,\n",
       " 427: 337,\n",
       " 454: 281,\n",
       " 412: 401,\n",
       " 404: 669,\n",
       " 401: 697,\n",
       " 436: 270,\n",
       " 410: 1139,\n",
       " 428: 374,\n",
       " 441: 111,\n",
       " 396: 867,\n",
       " 450: 17,\n",
       " 447: 225,\n",
       " 399: 441,\n",
       " 417: 2,\n",
       " 407: 317,\n",
       " 394: 390,\n",
       " 439: 7,\n",
       " 425: 94,\n",
       " 451: 30,\n",
       " 393: 2,\n",
       " 444: 88,\n",
       " 420: 194,\n",
       " 408: 1018,\n",
       " 452: 887,\n",
       " 443: 23,\n",
       " 437: 714,\n",
       " 406: 278,\n",
       " 438: 196,\n",
       " 460: 22,\n",
       " 463: 12,\n",
       " 461: 74,\n",
       " 464: 117,\n",
       " 462: 81,\n",
       " 459: 72,\n",
       " 458: 949,\n",
       " 466: 18,\n",
       " 456: 678,\n",
       " 465: 101,\n",
       " 457: 1,\n",
       " 487: 16,\n",
       " 506: 349,\n",
       " 501: 50,\n",
       " 499: 27,\n",
       " 475: 614,\n",
       " 477: 212,\n",
       " 485: 270,\n",
       " 508: 166,\n",
       " 473: 295,\n",
       " 486: 185,\n",
       " 493: 2,\n",
       " 468: 404,\n",
       " 483: 369,\n",
       " 471: 142,\n",
       " 511: 2340,\n",
       " 467: 2,\n",
       " 476: 1,\n",
       " 488: 183,\n",
       " 500: 2,\n",
       " 504: 843,\n",
       " 492: 281,\n",
       " 489: 565,\n",
       " 512: 828,\n",
       " 480: 169,\n",
       " 474: 10,\n",
       " 505: 282,\n",
       " 495: 2,\n",
       " 509: 578,\n",
       " 494: 8,\n",
       " 490: 644,\n",
       " 482: 25,\n",
       " 479: 152,\n",
       " 510: 212,\n",
       " 478: 133,\n",
       " 507: 216,\n",
       " 484: 184,\n",
       " 496: 703,\n",
       " 481: 202,\n",
       " 497: 26,\n",
       " 503: 1,\n",
       " 470: 102,\n",
       " 472: 569,\n",
       " 469: 589,\n",
       " 498: 791,\n",
       " 491: 533,\n",
       " 502: 2,\n",
       " 526: 6,\n",
       " 520: 7,\n",
       " 528: 37,\n",
       " 514: 5,\n",
       " 534: 297,\n",
       " 523: 148,\n",
       " 521: 7,\n",
       " 535: 52,\n",
       " 522: 23,\n",
       " 536: 806,\n",
       " 532: 116,\n",
       " 518: 13,\n",
       " 519: 159,\n",
       " 531: 45,\n",
       " 524: 26,\n",
       " 527: 46,\n",
       " 533: 57,\n",
       " 513: 7,\n",
       " 538: 139,\n",
       " 540: 27,\n",
       " 537: 683,\n",
       " 517: 324,\n",
       " 542: 2349,\n",
       " 539: 68,\n",
       " 529: 9,\n",
       " 516: 17,\n",
       " 515: 29,\n",
       " 530: 123,\n",
       " 541: 12,\n",
       " 525: 11,\n",
       " 572: 936,\n",
       " 653: 7,\n",
       " 579: 42,\n",
       " 555: 32,\n",
       " 636: 199,\n",
       " 622: 323,\n",
       " 557: 4,\n",
       " 577: 350,\n",
       " 614: 6,\n",
       " 578: 115,\n",
       " 552: 4,\n",
       " 589: 216,\n",
       " 558: 79,\n",
       " 605: 396,\n",
       " 631: 24,\n",
       " 643: 27,\n",
       " 595: 673,\n",
       " 575: 1343,\n",
       " 649: 287,\n",
       " 603: 213,\n",
       " 583: 475,\n",
       " 610: 9,\n",
       " 630: 27,\n",
       " 617: 400,\n",
       " 660: 12,\n",
       " 608: 264,\n",
       " 607: 279,\n",
       " 569: 22,\n",
       " 665: 2,\n",
       " 633: 10,\n",
       " 543: 29,\n",
       " 623: 26,\n",
       " 560: 1397,\n",
       " 581: 241,\n",
       " 618: 49,\n",
       " 574: 493,\n",
       " 556: 49,\n",
       " 585: 350,\n",
       " 644: 2,\n",
       " 655: 16,\n",
       " 634: 13,\n",
       " 546: 22,\n",
       " 609: 37,\n",
       " 604: 259,\n",
       " 612: 426,\n",
       " 627: 9,\n",
       " 652: 4,\n",
       " 580: 40,\n",
       " 554: 130,\n",
       " 564: 695,\n",
       " 626: 297,\n",
       " 600: 309,\n",
       " 629: 308,\n",
       " 639: 128,\n",
       " 648: 87,\n",
       " 621: 647,\n",
       " 570: 569,\n",
       " 597: 409,\n",
       " 566: 269,\n",
       " 616: 1007,\n",
       " 563: 288,\n",
       " 582: 784,\n",
       " 637: 379,\n",
       " 548: 278,\n",
       " 611: 800,\n",
       " 568: 200,\n",
       " 661: 64,\n",
       " 559: 23,\n",
       " 645: 43,\n",
       " 646: 13,\n",
       " 588: 131,\n",
       " 619: 22,\n",
       " 658: 1,\n",
       " 615: 1115,\n",
       " 606: 364,\n",
       " 638: 391,\n",
       " 662: 70,\n",
       " 625: 15,\n",
       " 567: 1,\n",
       " 594: 33,\n",
       " 642: 79,\n",
       " 549: 123,\n",
       " 664: 252,\n",
       " 551: 399,\n",
       " 573: 15,\n",
       " 602: 261,\n",
       " 553: 329,\n",
       " 596: 591,\n",
       " 592: 592,\n",
       " 584: 284,\n",
       " 640: 167,\n",
       " 601: 82,\n",
       " 620: 21,\n",
       " 624: 165,\n",
       " 565: 89,\n",
       " 544: 294,\n",
       " 654: 80,\n",
       " 659: 31,\n",
       " 587: 77,\n",
       " 632: 157,\n",
       " 561: 198,\n",
       " 650: 49,\n",
       " 550: 641,\n",
       " 647: 514,\n",
       " 656: 11,\n",
       " 562: 368,\n",
       " 576: 18,\n",
       " 598: 26,\n",
       " 593: 302,\n",
       " 547: 239,\n",
       " 545: 156,\n",
       " 663: 210,\n",
       " 657: 665,\n",
       " 591: 8,\n",
       " 599: 36,\n",
       " 666: 315,\n",
       " 590: 1190,\n",
       " 628: 140,\n",
       " 635: 3,\n",
       " 613: 428,\n",
       " 641: 376,\n",
       " 586: 73,\n",
       " 571: 54,\n",
       " 651: 32,\n",
       " 678: 1,\n",
       " 667: 1,\n",
       " 670: 1,\n",
       " 675: 1,\n",
       " 673: 119,\n",
       " 676: 127,\n",
       " 671: 54,\n",
       " 668: 57,\n",
       " 677: 345,\n",
       " 669: 302,\n",
       " 672: 30,\n",
       " 674: 2,\n",
       " 750: 36,\n",
       " 772: 421,\n",
       " 760: 8,\n",
       " 815: 650,\n",
       " 817: 261,\n",
       " 799: 27,\n",
       " 685: 249,\n",
       " 751: 109,\n",
       " 802: 866,\n",
       " 697: 758,\n",
       " 702: 274,\n",
       " 778: 305,\n",
       " 830: 147,\n",
       " 746: 13,\n",
       " 737: 18,\n",
       " 716: 181,\n",
       " 725: 172,\n",
       " 822: 156,\n",
       " 781: 338,\n",
       " 759: 641,\n",
       " 792: 326,\n",
       " 807: 18,\n",
       " 703: 116,\n",
       " 708: 51,\n",
       " 701: 439,\n",
       " 832: 67,\n",
       " 798: 493,\n",
       " 834: 5,\n",
       " 782: 180,\n",
       " 721: 209,\n",
       " 836: 372,\n",
       " 706: 26,\n",
       " 783: 116,\n",
       " 736: 72,\n",
       " 735: 102,\n",
       " 695: 834,\n",
       " 833: 195,\n",
       " 820: 58,\n",
       " 801: 337,\n",
       " 710: 793,\n",
       " 683: 18,\n",
       " 761: 280,\n",
       " 835: 132,\n",
       " 769: 16,\n",
       " 686: 276,\n",
       " 818: 444,\n",
       " 823: 584,\n",
       " 771: 21,\n",
       " 749: 55,\n",
       " 804: 16,\n",
       " 809: 282,\n",
       " 753: 264,\n",
       " 803: 353,\n",
       " 727: 249,\n",
       " 717: 568,\n",
       " 754: 44,\n",
       " 796: 90,\n",
       " 795: 766,\n",
       " 793: 62,\n",
       " 758: 581,\n",
       " 733: 588,\n",
       " 696: 303,\n",
       " 776: 226,\n",
       " 731: 156,\n",
       " 812: 92,\n",
       " 688: 51,\n",
       " 827: 196,\n",
       " 730: 117,\n",
       " 689: 24,\n",
       " 780: 64,\n",
       " 763: 5,\n",
       " 722: 196,\n",
       " 816: 4,\n",
       " 766: 130,\n",
       " 828: 1,\n",
       " 814: 664,\n",
       " 824: 235,\n",
       " 779: 199,\n",
       " 806: 13,\n",
       " 679: 135,\n",
       " 768: 80,\n",
       " 767: 164,\n",
       " 719: 22,\n",
       " 789: 247,\n",
       " 681: 295,\n",
       " 745: 521,\n",
       " 784: 72,\n",
       " 747: 97,\n",
       " 788: 1034,\n",
       " 774: 23,\n",
       " 741: 59,\n",
       " 773: 7,\n",
       " 786: 100,\n",
       " 790: 110,\n",
       " 680: 2,\n",
       " 691: 121,\n",
       " 805: 470,\n",
       " 734: 229,\n",
       " 715: 111,\n",
       " 765: 485,\n",
       " 739: 11,\n",
       " 684: 76,\n",
       " 752: 8,\n",
       " 690: 151,\n",
       " 743: 51,\n",
       " 777: 348,\n",
       " 787: 65,\n",
       " 829: 154,\n",
       " 682: 70,\n",
       " 748: 223,\n",
       " 714: 24,\n",
       " 755: 8,\n",
       " 819: 296,\n",
       " 826: 95,\n",
       " 825: 28,\n",
       " 797: 62,\n",
       " 729: 162,\n",
       " 724: 157,\n",
       " 757: 652,\n",
       " 808: 477,\n",
       " 707: 108,\n",
       " 718: 30,\n",
       " 711: 59,\n",
       " 811: 26,\n",
       " 693: 3,\n",
       " 775: 95,\n",
       " 705: 18,\n",
       " 692: 125,\n",
       " 800: 289,\n",
       " 813: 136,\n",
       " 704: 628,\n",
       " 740: 250,\n",
       " 744: 129,\n",
       " 700: 3,\n",
       " 821: 5,\n",
       " 770: 142,\n",
       " 794: 478,\n",
       " 764: 2,\n",
       " 712: 17,\n",
       " 698: 32,\n",
       " 694: 9,\n",
       " 791: 167,\n",
       " 831: 146,\n",
       " 687: 98,\n",
       " 709: 16,\n",
       " 728: 131,\n",
       " 810: 6,\n",
       " 732: 91,\n",
       " 785: 2,\n",
       " 742: 4,\n",
       " 738: 90,\n",
       " 713: 22,\n",
       " 726: 120,\n",
       " 699: 137,\n",
       " 756: 82,\n",
       " 720: 73,\n",
       " 723: 61,\n",
       " 762: 55,\n",
       " 868: 2,\n",
       " 838: 46,\n",
       " 848: 118,\n",
       " 869: 23,\n",
       " 877: 358,\n",
       " 885: 587,\n",
       " 872: 6,\n",
       " 862: 86,\n",
       " 841: 40,\n",
       " 847: 202,\n",
       " 878: 556,\n",
       " 844: 382,\n",
       " 853: 2,\n",
       " 856: 2,\n",
       " 881: 84,\n",
       " 894: 2,\n",
       " 883: 285,\n",
       " 849: 33,\n",
       " 880: 420,\n",
       " 840: 127,\n",
       " 857: 239,\n",
       " 864: 1025,\n",
       " 855: 5,\n",
       " 892: 182,\n",
       " 852: 31,\n",
       " 893: 4,\n",
       " 888: 707,\n",
       " 861: 5,\n",
       " 876: 2,\n",
       " 895: 35,\n",
       " 875: 10,\n",
       " 873: 4,\n",
       " 867: 85,\n",
       " 865: 1140,\n",
       " 837: 32,\n",
       " 891: 2,\n",
       " 863: 63,\n",
       " 854: 9,\n",
       " 886: 2,\n",
       " 858: 2,\n",
       " 871: 42,\n",
       " 846: 164,\n",
       " 879: 3,\n",
       " 884: 2,\n",
       " 874: 2,\n",
       " 845: 4,\n",
       " 851: 5,\n",
       " 843: 2,\n",
       " 842: 4,\n",
       " 860: 248,\n",
       " 839: 76,\n",
       " 882: 4,\n",
       " 887: 2,\n",
       " 889: 36,\n",
       " 890: 33,\n",
       " 866: 95,\n",
       " 850: 427,\n",
       " 859: 13,\n",
       " 870: 67,\n",
       " 923: 56,\n",
       " 922: 47,\n",
       " 931: 519,\n",
       " 897: 252,\n",
       " 903: 186,\n",
       " 935: 35,\n",
       " 920: 265,\n",
       " 936: 155,\n",
       " 945: 1,\n",
       " 929: 16,\n",
       " 924: 342,\n",
       " 918: 99,\n",
       " 938: 3,\n",
       " 910: 472,\n",
       " 908: 80,\n",
       " 925: 290,\n",
       " 914: 1075,\n",
       " 926: 13,\n",
       " 909: 96,\n",
       " 943: 89,\n",
       " 916: 1,\n",
       " 902: 214,\n",
       " 933: 204,\n",
       " 934: 41,\n",
       " 942: 145,\n",
       " 915: 986,\n",
       " 919: 89,\n",
       " 900: 265,\n",
       " 932: 161,\n",
       " 901: 119,\n",
       " 898: 109,\n",
       " 937: 469,\n",
       " 940: 257,\n",
       " 911: 26,\n",
       " 927: 125,\n",
       " 928: 1004,\n",
       " 917: 29,\n",
       " 939: 322,\n",
       " 907: 139,\n",
       " 930: 350,\n",
       " 896: 120,\n",
       " 904: 12,\n",
       " 899: 773,\n",
       " 913: 13,\n",
       " 941: 527,\n",
       " 944: 135,\n",
       " 912: 845,\n",
       " 905: 254,\n",
       " 921: 3,\n",
       " 906: 152,\n",
       " 975: 48,\n",
       " 948: 133,\n",
       " 988: 47,\n",
       " 977: 76,\n",
       " 983: 320,\n",
       " 980: 4,\n",
       " 972: 115,\n",
       " 979: 12,\n",
       " 970: 231,\n",
       " 973: 333,\n",
       " 954: 895,\n",
       " 956: 159,\n",
       " 981: 1014,\n",
       " 978: 259,\n",
       " 952: 34,\n",
       " 968: 27,\n",
       " 971: 252,\n",
       " 982: 475,\n",
       " 969: 15,\n",
       " 958: 155,\n",
       " 992: 236,\n",
       " 951: 36,\n",
       " 974: 34,\n",
       " 947: 144,\n",
       " 955: 5,\n",
       " 966: 20,\n",
       " 990: 33,\n",
       " 963: 274,\n",
       " 991: 853,\n",
       " 949: 8,\n",
       " 976: 289,\n",
       " 953: 199,\n",
       " 960: 57,\n",
       " 985: 564,\n",
       " 987: 283,\n",
       " 962: 35,\n",
       " 961: 274,\n",
       " 984: 18,\n",
       " 959: 277,\n",
       " 965: 363,\n",
       " 986: 530,\n",
       " 950: 486,\n",
       " 946: 828,\n",
       " 967: 648,\n",
       " 964: 351,\n",
       " 957: 596,\n",
       " 989: 71,\n",
       " 1038: 5,\n",
       " 1091: 28,\n",
       " 1089: 139,\n",
       " 1119: 18,\n",
       " 1084: 176,\n",
       " 1019: 269,\n",
       " 1095: 39,\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.dfs # Document frequencies: token_id -> how many documents contain this token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 addit\n",
      "1 bodi\n",
      "2 bricklin\n",
      "3 bring\n",
      "4 bumper\n",
      "5 call\n",
      "6 colleg\n",
      "7 door\n",
      "8 earli\n",
      "9 engin\n",
      "10 enlighten\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 tokens from the vocab (dictionary)\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n= 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<5000 unique tokens: ['addit', 'bodi', 'bring', 'bumper', 'call']...>\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lerxst', 'thing', 'subject', 'nntp', 'post', 'host', 'organ', 'univers', 'maryland', 'colleg', 'park', 'line', 'wonder', 'enlighten', 'door', 'sport', 'look', 'late', 'earli', 'call', 'bricklin', 'door', 'small', 'addit', 'bumper', 'separ', 'rest', 'bodi', 'know', 'tellm', 'model', 'engin', 'spec', 'year', 'product', 'histori', 'info', 'funki', 'look', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.doc2bow(processed_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11, 1), (20, 1), (23, 1), (29, 5), (103, 1), (115, 1), (123, 1), (196, 1), (296, 1), (337, 1), (381, 1), (394, 1), (433, 1), (481, 1), (496, 1), (520, 1), (524, 1), (526, 3), (561, 2), (754, 3), (764, 1), (831, 1), (884, 1), (940, 1), (1012, 1), (1013, 1), (1014, 1), (1015, 1), (1016, 2), (1017, 1), (1018, 1), (1019, 3), (1020, 1), (1021, 2), (1022, 2), (1023, 1), (1024, 1), (1025, 1), (1026, 1), (1027, 1), (1028, 1), (1029, 1), (1030, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow_corpus[20]) # BoW representaion of the 21st doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keith', 'caltech', 'keith', 'allan', 'schneider', 'subject', 'pompous', 'organ', 'california', 'institut', 'technolog', 'pasadena', 'line', 'nntp', 'post', 'host', 'punish', 'caltech', 'livesey', 'solntz', 'livesey', 'write', 'littl', 'thing', 'refer', 'germani', 'clear', 'peopl', 'say', 'similar', 'thing', 'germani', 'true', 'give', 'exampl', 'pevas', 'anti', 'semit', 'german', 'christian', 'hitler', 'arriv', 'social', 'rank', 'imperail', 'germani', 'austria', 'distinguish', 'jew', 'rest', 'popul', 'like', 'littl', 'thing', 'order', 'wors', 'motto', 'think', 'motto', 'littl', 'thing', 'lead', 'wors', 'thing', 'keith']\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 11 (\"host\") appears 1 time.\n",
      "Word 20 (\"nntp\") appears 1 time.\n",
      "Word 23 (\"rest\") appears 1 time.\n",
      "Word 29 (\"thing\") appears 5 time.\n",
      "Word 103 (\"give\") appears 1 time.\n",
      "Word 115 (\"like\") appears 1 time.\n",
      "Word 123 (\"peopl\") appears 1 time.\n",
      "Word 196 (\"clear\") appears 1 time.\n",
      "Word 296 (\"say\") appears 1 time.\n",
      "Word 337 (\"think\") appears 1 time.\n",
      "Word 381 (\"refer\") appears 1 time.\n",
      "Word 394 (\"true\") appears 1 time.\n",
      "Word 433 (\"technolog\") appears 1 time.\n",
      "Word 481 (\"christian\") appears 1 time.\n",
      "Word 496 (\"exampl\") appears 1 time.\n",
      "Word 520 (\"jew\") appears 1 time.\n",
      "Word 524 (\"lead\") appears 1 time.\n",
      "Word 526 (\"littl\") appears 3 time.\n",
      "Word 561 (\"wors\") appears 2 time.\n",
      "Word 754 (\"keith\") appears 3 time.\n",
      "Word 764 (\"punish\") appears 1 time.\n",
      "Word 831 (\"california\") appears 1 time.\n",
      "Word 884 (\"institut\") appears 1 time.\n",
      "Word 940 (\"similar\") appears 1 time.\n",
      "Word 1012 (\"allan\") appears 1 time.\n",
      "Word 1013 (\"anti\") appears 1 time.\n",
      "Word 1014 (\"arriv\") appears 1 time.\n",
      "Word 1015 (\"austria\") appears 1 time.\n",
      "Word 1016 (\"caltech\") appears 2 time.\n",
      "Word 1017 (\"distinguish\") appears 1 time.\n",
      "Word 1018 (\"german\") appears 1 time.\n",
      "Word 1019 (\"germani\") appears 3 time.\n",
      "Word 1020 (\"hitler\") appears 1 time.\n",
      "Word 1021 (\"livesey\") appears 2 time.\n",
      "Word 1022 (\"motto\") appears 2 time.\n",
      "Word 1023 (\"order\") appears 1 time.\n",
      "Word 1024 (\"pasadena\") appears 1 time.\n",
      "Word 1025 (\"popul\") appears 1 time.\n",
      "Word 1026 (\"rank\") appears 1 time.\n",
      "Word 1027 (\"schneider\") appears 1 time.\n",
      "Word 1028 (\"semit\") appears 1 time.\n",
      "Word 1029 (\"social\") appears 1 time.\n",
      "Word 1030 (\"solntz\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# get the BoW representation for all the processed documents\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Algorithm\n",
    "Inputs to the LDA: Collections of documents & no. of topics to be identified.\n",
    "\n",
    "Steps for LDA:\n",
    "1. Assign a random topic to each word in each document.\n",
    "2. Cal the prob of each word (term) belonging to each topic, based on the words that are currently assigned to each topics.\n",
    "3. Reassign each word to a new topic, based on the calculated probabilites.\n",
    "\n",
    "4. Repeat 2-3, until the topic assginment for the words converge and the algo reaches a stable state. \n",
    "\n",
    "5. Once the Algo has converged, use it to discover the topics in the text data and the words that are associated with each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 8, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"presid\" + 0.004*\"clinton\" + 0.004*\"bike\" + 0.003*\"netcom\" + 0.003*\"homosexu\" + 0.003*\"run\" + 0.003*\"talk\" + 0.003*\"pitch\" + 0.003*\"money\" + 0.003*\"virginia\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.009*\"govern\" + 0.007*\"armenian\" + 0.006*\"israel\" + 0.005*\"kill\" + 0.005*\"isra\" + 0.004*\"turkish\" + 0.004*\"american\" + 0.004*\"weapon\" + 0.004*\"jew\" + 0.004*\"countri\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.017*\"game\" + 0.015*\"team\" + 0.011*\"play\" + 0.009*\"player\" + 0.008*\"hockey\" + 0.006*\"season\" + 0.005*\"canada\" + 0.005*\"leagu\" + 0.005*\"score\" + 0.004*\"divis\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.010*\"card\" + 0.009*\"window\" + 0.007*\"driver\" + 0.007*\"sale\" + 0.006*\"price\" + 0.005*\"speed\" + 0.005*\"appl\" + 0.005*\"video\" + 0.005*\"monitor\" + 0.004*\"sell\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.015*\"file\" + 0.010*\"program\" + 0.009*\"window\" + 0.006*\"encrypt\" + 0.006*\"chip\" + 0.006*\"imag\" + 0.006*\"data\" + 0.006*\"avail\" + 0.005*\"version\" + 0.005*\"code\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.013*\"space\" + 0.010*\"nasa\" + 0.006*\"scienc\" + 0.005*\"orbit\" + 0.005*\"research\" + 0.004*\"launch\" + 0.003*\"pitt\" + 0.003*\"earth\" + 0.003*\"develop\" + 0.003*\"bank\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.034*\"drive\" + 0.015*\"scsi\" + 0.010*\"disk\" + 0.009*\"hard\" + 0.009*\"control\" + 0.006*\"columbia\" + 0.006*\"washington\" + 0.005*\"car\" + 0.005*\"uiuc\" + 0.004*\"floppi\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.012*\"christian\" + 0.008*\"jesus\" + 0.006*\"exist\" + 0.005*\"bibl\" + 0.005*\"moral\" + 0.005*\"word\" + 0.005*\"religion\" + 0.005*\"church\" + 0.004*\"life\" + 0.004*\"claim\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.609176194217716"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cohenrence of an LDA model is a measure of how well the LDA model has discovered the underlying topics\n",
    "# from the collection of documents.\n",
    "# High coherence value indicates that the topics are coherent and interpretable\n",
    "# low coherence value indicates that the topics are difficult to interpret or overfitting the data (?)\n",
    "\n",
    "cm = CoherenceModel(model=lda_model, corpus=bow_corpus, coherence='u_mass')\n",
    "coherence = cm.get_coherence()  # get coherence value\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence metrics => \n",
    "# 'u_mass'  >>> most common, based on the concept of pointwise mutual information.\n",
    "# c_v >>> normalised pointwise mutual information.\n",
    "# c_uci >> based on the concept of relative entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for doc in processed_docs:\n",
    "    sent = [' '.join(tokens) for doc in processed_docs for tokens in doc]\n",
    "    docs.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(\"'texts' should be provided for %s coherence.\", 'c_v')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mCoherenceModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc_v\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m coherence \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mget_coherence()  \u001b[38;5;66;03m# get coherence value\u001b[39;00m\n\u001b[0;32m      3\u001b[0m coherence\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\gensim\\models\\coherencemodel.py:207\u001b[0m, in \u001b[0;36mCoherenceModel.__init__\u001b[1;34m(self, model, topics, texts, corpus, dictionary, window_size, keyed_vectors, coherence, topn, processes)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m coherence \u001b[38;5;129;01min\u001b[39;00m SLIDING_WINDOW_BASED:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be provided for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m coherence.\u001b[39m\u001b[38;5;124m\"\u001b[39m, coherence)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m coherence is not currently supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m, coherence)\n",
      "\u001b[1;31mValueError\u001b[0m: (\"'texts' should be provided for %s coherence.\", 'c_v')"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(model=lda_model, corpus=processed_docs, coherence='c_v')\n",
    "coherence = cm.get_coherence()  # get coherence value\n",
    "coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
